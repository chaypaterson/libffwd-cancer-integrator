two-hit

Simulates first passage times in a simple two-hit model. The idea is to refute
an idea about cancer incidence in old age: the mean field approximation should
be valid for thousands of years, and deviations from Armitage-Doll and
Moolgavkar-Lubeck forms represent observational artifacts or new biology.

Source: (I think) R. Meza PNAS 2008

What I really think is going on is the mean-field approximation breaks down
much earlier, so cancer incidence in old age becomes selection-limited rather
than mutation-limited. This has the effect that the cumulative incidence
should deviate very strongly from the mean-field prediction back to something
like O(e^{- s t}).

When I think it should break down:

t ~ ln(s / mu) / s

Ideally this should all tie in with my ongoing project to find a useful "exact
solution" to a birth-death process that proves the above limit more rigorously.

What the simulations should be of:
----------------------------------

        /\
        |V
O ----> O ----> O

   mu0  s  mu1

Two steps, 3 populations (n0, n1, n2). n1 has an advantage/growth rate s.

Use the Gillespie algorithm for an exact sample of the master equation:

Gamma = mu0 * n0 + (mu1 + s) * n1

x = Unif(0,Gamma)

Pr mut0 = (mu0 * n0) / Gamma
Pr birth = (s * n1) / Gamma
Pr mut1 = (mu1 * n1) / Gamma

t += Exp(0, 1/Gamma)

How long does it take for an n2 to appear?

Language they should be in:
---------------------------

C/++

Plots should be automatically generated using Python/Matplotlib.

